<html class="notion-html"><head lang="en"><meta charset="utf-8"/><meta content="width=device-width,height=device-height,initial-scale=1,maximum-scale=1,user-scalable=no,viewport-fit=cover" name="viewport"/><title>4.2. 卷积神经网络实例介绍</title><meta content="en_US" property="og:locale"/><link href="/images/favicon.ico" rel="shortcut icon" type="image/x-icon"/><link href="/images/logo-ios.png" rel="apple-touch-icon"/><meta content="yes" name="apple-mobile-web-app-capable"/><meta content="telephone=no" name="format-detection"/><meta content="no" name="msapplication-tap-highlight"/><link href="e218a1aef6df86309cb95b61e446888efa3b0379.css" media="print" rel="stylesheet"/><link href="e1d809d762eeca23edf0cb31bb17bf3c703085f5.css" rel="stylesheet"/><link href="ea336c780f905bf8e5199e24de64f0cf84362824.css" rel="stylesheet"/></head><body class="notion-body"><style>body{background:#fff}body.dark{background:#191919}@keyframes startup-shimmer-animation{0%{transform:translateX(-100%) translateZ(0)}100%{transform:translateX(100%) translateZ(0)}}@keyframes startup-shimmer-fade-in{0%{opacity:0}100%{opacity:1}}@keyframes startup-spinner-rotate{0%{transform:rotate(0) translateZ(0)}100%{transform:rotate(360deg) translateZ(0)}}#initial-loading-spinner{position:fixed;height:100vh;width:100vw;z-index:-1;display:none;align-items:center;justify-content:center;opacity:.5}#initial-loading-spinner svg{height:24px;width:24px;animation:startup-spinner-rotate 1s linear infinite;transform-origin:center center;pointer-events:none}#skeleton{background:#fff;position:fixed;height:100vh;width:100vw;z-index:-1;display:none;overflow:hidden}#initial-loading-spinner.show,#skeleton.show{display:flex}body.dark #skeleton{background:#191919}.notion-front-page #skeleton,.notion-mobile #skeleton{display:none}#skeleton-sidebar{background-color:#fbfbfa;box-shadow:inset -1px 0 0 0 rgba(0,0,0,.025);display:flex;width:240px;flex-direction:column;padding:12px 14px;overflow:hidden}body.dark #skeleton-sidebar{background-color:#202020;box-shadow:inset -1px 0 0 0 rgba(255,255,255,.05)}#skeleton.isElectron #skeleton-sidebar{padding-top:46px}#skeleton .row{display:flex;margin-bottom:8px;align-items:center}#skeleton .row.fadein{animation:1s ease-in 0s 1 normal both running startup-shimmer-fade-in}#skeleton .chevron{width:12px;height:12px;display:block;margin-right:4px;fill:rgba(227,226,224,.5)}body.dark #skeleton .chevron{fill:#2f2f2f}.startup-shimmer{background:rgba(227,226,224,.5);overflow:hidden;position:relative}body.dark .startup-shimmer{background:#2f2f2f}.startup-shimmer::before{content:"";position:absolute;height:100%;width:100%;z-index:1;animation:1s linear infinite startup-shimmer-animation;background:linear-gradient(90deg,transparent 0,rgba(255,255,255,.4) 50%,transparent 100%)}body.dark .startup-shimmer::before{background:linear-gradient(90deg,transparent 0,rgba(86,86,86,.4) 50%,transparent 100%)}#skeleton .icon{width:20px;height:20px;border-radius:4px}#skeleton .text{height:10px;border-radius:10px}#skeleton .draggable{-webkit-app-region:drag;position:absolute;top:0;left:0;width:100%;height:36px;display:none}#skeleton.isElectron .draggable{display:block}</style><style id="scroll-properties">
			::-webkit-scrollbar {
				width: 10px;
				height: 10px;
			}
			::-webkit-scrollbar {
				background: transparent;
			}
			::-webkit-scrollbar-track {
				background: #EDECE9;
			}
			::-webkit-scrollbar-thumb {
				background:#D3D1CB;
			}
			::-webkit-scrollbar-thumb:hover {
				background:#AEACA6;
			}
		</style><div id="notion-app"><div class="notion-app-inner notion-light-theme" style='color: rgb(55, 53, 47); fill: currentcolor; line-height: 1.5; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; -webkit-font-smoothing: auto; background-color: white;'><div style="height: 100%;"><div class="notion-cursor-listener" style="width: 100vw; height: 100%; position: relative; display: flex; flex: 1 1 0%; background: white; cursor: text;"><div class="" style="display: flex; flex-direction: column; width: 100%; overflow: hidden;"><div style="max-width: 100vw; z-index: 100; background: white; user-select: none;"><div class="notion-topbar" style="width: 100%; max-width: 100vw; height: 45px; opacity: 1; transition: opacity 700ms ease 0s, color 700ms ease 0s; position: relative;"><div style="display: flex; justify-content: space-between; align-items: center; overflow: hidden; height: 45px; padding-left: 12px; padding-right: 10px;"><div class="notranslate shadow-cursor-breadcrumb" style="display: flex; align-items: center; line-height: 1.2; font-size: 14px; height: 100%; flex-grow: 0; margin-right: 8px; min-width: 0px;"><div class="notion-selectable notion-page-block" data-block-id="6f173729-5884-4d32-8452-4cbeea3e462c" style="display: flex; align-items: center; min-width: 0px;"><a href="index.html" rel="noopener noreferrer" style="display: flex; color: rgb(55, 53, 47); text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: inherit; line-height: 1.2; min-width: 0px; padding: 2px;"><div style="display: flex; align-items: center; min-width: 0px;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px; font-weight: 500;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 14px; width: 14px; font-size: 14px; line-height: 1; margin-left: 0px; color: black;"><img alt="🌃" aria-label="🌃" class="notion-emoji" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" style="width: 100%;
height: 100%;
background: url(f87457017f44d1d87f6d662556796277387c1c28.png) 8.47458% 11.8644%/6000% 6000%"/></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">BMPixel网络日志</div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div class="notion-selectable notion-collection_view-block" data-block-id="27dbe900-3c41-4c13-bd5a-432418911021" style="display: flex; align-items: center; min-width: 0px;"><a href="27dbe9003c414c13bd5a432418911021.html" rel="noopener noreferrer" style="display: flex; color: rgb(55, 53, 47); text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: inherit; line-height: 1.2; min-width: 0px; padding: 2px;"><div style="display: flex; align-items: center; min-width: 0px;"><div class="notion-record-icon notranslate" style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px; border-radius: 0.25em; flex-shrink: 0; margin-right: 6px; font-weight: 500;"><div style="display: flex; align-items: center; justify-content: center; height: 20px; width: 20px;"><div style="height: 14px; width: 14px; font-size: 14px; line-height: 1; margin-left: 0px; color: black;"><img alt="🌃" aria-label="🌃" class="notion-emoji" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" style="width: 100%;
height: 100%;
background: url(f87457017f44d1d87f6d662556796277387c1c28.png) 8.47458% 11.8644%/6000% 6000%"/></div></div></div><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 160px;">网络日志</div></div></a></div><span style="margin-left: 2px; margin-right: 2px; color: rgba(55, 53, 47, 0.5);">/</span><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 1; white-space: nowrap; height: 24px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 6px; padding-right: 6px; color: rgb(55, 53, 47);" tabindex="0"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; max-width: 240px;">4.2. 卷积神经网络实例介绍</div></div></div><div style="flex-grow: 1; flex-shrink: 1;"></div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="searchNew" style="width: 14px; height: 14px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 17 17"><path d="M6.78027 13.6729C8.24805 13.6729 9.60156 13.1982 10.709 12.4072L14.875 16.5732C15.0684 16.7666 15.3232 16.8633 15.5957 16.8633C16.167 16.8633 16.5713 16.4238 16.5713 15.8613C16.5713 15.5977 16.4834 15.3516 16.29 15.1582L12.1504 11.0098C13.0205 9.86719 13.5391 8.45215 13.5391 6.91406C13.5391 3.19629 10.498 0.155273 6.78027 0.155273C3.0625 0.155273 0.0214844 3.19629 0.0214844 6.91406C0.0214844 10.6318 3.0625 13.6729 6.78027 13.6729ZM6.78027 12.2139C3.87988 12.2139 1.48047 9.81445 1.48047 6.91406C1.48047 4.01367 3.87988 1.61426 6.78027 1.61426C9.68066 1.61426 12.0801 4.01367 12.0801 6.91406C12.0801 9.81445 9.68066 12.2139 6.78027 12.2139Z"></path></svg>Search</div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0">Duplicate</div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: flex; align-items: center; justify-content: center; width: 32px; height: 28px; border-radius: 3px;" tabindex="0"><svg class="dots" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden;" viewBox="0 0 13 3"><g><path d="M3,1.5A1.5,1.5,0,1,1,1.5,0,1.5,1.5,0,0,1,3,1.5Z"></path><path d="M8,1.5A1.5,1.5,0,1,1,6.5,0,1.5,1.5,0,0,1,8,1.5Z"></path><path d="M13,1.5A1.5,1.5,0,1,1,11.5,0,1.5,1.5,0,0,1,13,1.5Z"></path></g></svg></div><div style="flex: 0 0 auto; width: 1px; height: 16px; margin-left: 8px; margin-right: 8px; background: rgba(55, 53, 47, 0.16);"></div><div role="button" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: inline-flex; align-items: center; flex-shrink: 0; white-space: nowrap; height: 28px; border-radius: 4px; font-size: 14px; line-height: 1.2; min-width: 0px; padding-left: 8px; padding-right: 8px; color: rgb(55, 53, 47);" tabindex="0"><svg class="notionLogo" style="width: 18px; height: 18px; display: block; fill: inherit; flex-shrink: 0; backface-visibility: hidden; margin-right: 6px;" viewBox="0 0 120 126"><path d="M 20.6927 21.9315C 24.5836 25.0924 26.0432 24.8512 33.3492 24.3638L 102.228 20.2279C 103.689 20.2279 102.474 18.7705 101.987 18.5283L 90.5477 10.2586C 88.3558 8.55699 85.4356 6.60818 79.8387 7.09563L 13.1433 11.9602C 10.711 12.2014 10.2251 13.4175 11.1939 14.3924L 20.6927 21.9315ZM 24.8281 37.9835L 24.8281 110.456C 24.8281 114.351 26.7745 115.808 31.1553 115.567L 106.853 111.187C 111.236 110.946 111.724 108.267 111.724 105.103L 111.724 33.1169C 111.724 29.958 110.509 28.2544 107.826 28.4976L 28.721 33.1169C 25.8018 33.3622 24.8281 34.8225 24.8281 37.9835ZM 99.5567 41.8711C 100.042 44.0622 99.5567 46.2512 97.3618 46.4974L 93.7143 47.2241L 93.7143 100.728C 90.5477 102.43 87.6275 103.403 85.1942 103.403C 81.2983 103.403 80.3226 102.186 77.4044 98.54L 53.5471 61.087L 53.5471 97.3239L 61.0964 99.0275C 61.0964 99.0275 61.0964 103.403 55.0057 103.403L 38.2148 104.377C 37.727 103.403 38.2148 100.973 39.9179 100.486L 44.2996 99.2717L 44.2996 51.36L 38.2158 50.8725C 37.728 48.6815 38.9431 45.5225 42.3532 45.2773L 60.3661 44.0631L 85.1942 82.0036L 85.1942 48.4402L 78.864 47.7136C 78.3781 45.0351 80.3226 43.0902 82.7569 42.849L 99.5567 41.8711ZM 7.5434 5.39404L 76.9175 0.285276C 85.4366 -0.445402 87.6285 0.0440428 92.983 3.93368L 115.128 19.4982C 118.782 22.1747 120 22.9034 120 25.8211L 120 111.187C 120 116.537 118.051 119.701 111.237 120.185L 30.6734 125.05C 25.5584 125.294 23.124 124.565 20.4453 121.158L 4.13735 99.9994C 1.21516 96.1048 0 93.191 0 89.7819L 0 13.903C 0 9.5279 1.94945 5.8785 7.5434 5.39404Z"></path></svg>Try Notion</div></div></div><div style="width: calc(100% - 0px); user-select: none;"></div></div><div class="notion-frame" style="flex-grow: 0; flex-shrink: 1; display: flex; flex-direction: column; background: white; z-index: 1; height: calc(100vh - 45px); max-height: 100%; position: relative; width: 1920px;"><div class="notion-scroller vertical" style="display: flex; flex-direction: column; z-index: 1; flex-grow: 1; position: relative; align-items: center; margin-right: 0px; margin-bottom: 0px; overflow: hidden auto;"><div style="position: absolute; top: 0px; left: 0px;"><div></div></div><div class="whenContentEditable" data-content-editable-root="true" style="caret-color: rgb(55, 53, 47); width: 100%; display: flex; flex-direction: column; position: relative; align-items: center; flex-grow: 1; --whenContentEditable--WebkitUserModify:read-write-plaintext-only;"><span style="height: 1px; width: 1px;"></span><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0; z-index: 2;"><div style="position: relative; width: 100%; display: flex; flex-direction: column; align-items: center; height: 30vh; cursor: default;"><div style="width: 100%; cursor: inherit;"><div style="display: grid; width: 100%; height: 30vh;"><div style="grid-area: 1 / 1 / auto / auto; width: 100%; height: 100%;"><img referrerpolicy="same-origin" src="c7ae41a6ae3c4ecb2aa43884cc8ecd579e851372.jpg" style="display: block; object-fit: cover; border-radius: 0px; width: 100%; height: 30vh; opacity: 1; object-position: center 50%;"/></div></div></div><div aria-hidden="true" style='background: rgba(0, 0, 0, 0.4); border-radius: 3px; color: white; font-size: 12px; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; width: 180px; left: calc(50% - 90px); padding: 0.3em 1.5em; pointer-events: none; position: absolute; top: calc(50% - 10px); text-align: center; opacity: 0;'>Drag image to reposition</div></div></div><div style="width: 100%; display: flex; justify-content: center; z-index: 3; flex-shrink: 0;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div style="max-width: 100%; padding-left: calc(96px + env(safe-area-inset-left)); width: 100%;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" style="user-select: none; --pseudoSelection--background:transparent; pointer-events: none;"><div class="notion-page-controls" style='display: flex; justify-content: flex-start; flex-wrap: wrap; margin-top: 16px; margin-bottom: 4px; margin-left: -1px; color: rgba(55, 53, 47, 0.5); font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; height: 24px; pointer-events: auto;'></div></div><div style="padding-right: calc(96px + env(safe-area-inset-right));"><div><div class="notion-selectable notion-page-block" data-block-id="4f2b09a9-de97-4bdf-8049-ba4c02dd3de2" style='color: rgb(55, 53, 47); font-weight: 700; line-height: 1.2; font-size: 40px; font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; cursor: text; display: flex; align-items: center;'><div contenteditable="false" data-content-editable-leaf="true" placeholder="Untitled" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">4.2. 卷积神经网络实例介绍</div></div><div style="margin-left: 4px;"></div></div></div></div></div><div style="width: 100%; display: flex; flex-direction: column; align-items: center; flex-shrink: 0; flex-grow: 0;"><div contenteditable="false" data-content-editable-void="true" style="padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right)); max-width: 100%; width: 100%;"><div style="width: 100%; font-size: 14px;"><div style="width: 100%; max-width: 100%; padding: 8px 0px; margin: 0px auto;"><div style="width: 100%; max-width: 100%; padding-top: 8px; margin: 0px auto;"><div style="padding-bottom: 8px;"><div style="margin: 0px;"></div></div></div></div></div><div style="width: 100%; height: 1px; background: rgba(55, 53, 47, 0.09); margin-bottom: 8px;"></div></div></div></div></div><main style="display: flex; width: 100%; justify-content: center; padding-top: 5px;"><div style="max-width: 100%; min-width: 0px; width: 900px;"><div class="notion-page-content" style="flex-shrink: 0; flex-grow: 1; max-width: 100%; display: flex; align-items: flex-start; flex-direction: column; font-size: 16px; line-height: 1.5; width: 100%; z-index: 4; padding-bottom: 30vh; padding-left: calc(96px + env(safe-area-inset-left)); padding-right: calc(96px + env(safe-area-inset-right));"><div class="notion-selectable notion-header-block" data-block-id="b2a714e3-289d-41e2-9ca2-51e18195f425" style="width: 100%; max-width: 1718px; margin-top: 2em; margin-bottom: 4px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 1" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.875em; line-height: 1.3;">卷积神经网络实例介绍</div></div></div><div class="notion-selectable notion-text-block" data-block-id="72f0395e-974e-4409-ad7a-7f2117712344" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">在这个笔记中我们来按照时间顺序介绍一些卷积神经网络的案例。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="3f99fcf0-9a50-4713-a3e6-e6b9212bfae4" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">为什么要了解别人设计的网络模型呢？计算机视觉研究中的大量研究都集中在如何把各种不同的基本构件组合起来，形成有效的卷积神经网络。我们如果想要快速设计出一个自己的很好使的卷积神经网络，最直观的方式之一就是去看一些案例，就像很多人通过看别人的代码来学习编程一样，通过研究别人构建有效组件的案例是个不错的办法。实际上在计算机视觉任务中表现良好的神经网络框架往往也适用于其它任务。也就是说，如果有人已经训练或者计算出擅长识别猫、狗、人的神经网络或者神经网络框架，而你的计算机视觉识别任务是构建一个自动驾驶汽车，我们完全可以借鉴别人的神经网络框架来解决自己的问题。</div></div></div></div><div class="notion-selectable notion-sub_header-block" data-block-id="3e62268b-b300-4dc1-9896-ae898f0ce0ac" style="width: 100%; max-width: 1718px; margin-top: 1.4em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 2" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.5em; line-height: 1.3;">几个经典网络模型</div></div></div><div class="notion-selectable notion-text-block" data-block-id="428f07db-3a71-4852-a923-4bd0c83e40ab" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">我们将按照时间顺序介绍三个经典网络模型：LeNet-5，AlexNet，VGG</div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="9d426afc-94c8-467f-ab80-29feb404d3bc" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">LeNet-5</div></div></div><div class="notion-selectable notion-image-block" data-block-id="79fea26e-c314-4d89-b7f6-ea50496ba08b" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="10eb9d5647f9c461c89e9a2ed01d2eae872bbeb0.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="6fa9de4c-ebf4-45a1-99ec-9f4f32d0a3fd" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">从左往右看，随着网络越来越深，图像的高度和宽度在缩小，从最初的 32×32 缩小到 28×28，再到 14×14、10×10，最后只有 5×5。与此同时，随着网络层次的加深，通道数量一直在增加，从 1 增加到 6 个，再到 16 个。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="e75e5eba-b78b-4556-b336-96f1cd75a0eb" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">特点：</div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="3c3518c5-3eec-49ef-a295-0a02da3c66e3" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">LeNet-5 针对灰度图像而训练，因此输入图片的通道数为 1。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="63df4ff8-ed8e-4dfe-96c7-0df40a959308" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">该模型总共包含了约 6 万个参数，非常的少。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="852e68e4-46a5-4099-bc3a-a333bbeead1b" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">典型的 LeNet-5 结构包含卷积层（CONV layer），池化层（POOL layer）和全连接层（FC layer），排列顺序一般为 CONV layer-&gt;POOL layer-&gt;CONV layer-&gt;POOL layer-&gt;FC layer-&gt;FC layer-&gt;OUTPUT layer。一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="e9ed2ee3-375f-45b6-945c-7ccb1548838a" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。</div></div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="abb0e78d-1054-4eb9-aaeb-ff30ad80580b" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">AlexNet</div></div></div><div class="notion-selectable notion-image-block" data-block-id="84c0ebe2-32b1-4c2a-82e7-a0f30b20ff97" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="0fe28bf54e0c10e55a7ed86ad5fd937792beb2c6.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="5550f70d-2963-4b9d-9f18-b8645947c41a" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">特点：</div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="904a3eb7-3065-452f-a70a-5f51e4802cb7" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">AlexNet 模型与 LeNet-5 模型类似，但是更复杂，包含约 6000 万个参数。另外，AlexNet 模型使用了 ReLU 函数。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="9a19dd3f-46b2-4537-b5e7-53d51c1e45d5" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">AlexNet有许多结构非常相似的基本构造模块。</div></div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="874620f3-30b8-468d-99f2-8885f4e99249" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">VGG</div></div></div><div class="notion-selectable notion-image-block" data-block-id="1547a9ff-36a6-4d43-9bd1-68d18e98a8ab" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="cb1099ebc2826692453ab0f56f9a5e699fd851aa.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="7e9ea192-94cf-470f-b124-04103d483f1e" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">特点：</div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="5038096c-54e9-4a25-af36-c2f63aea1c43" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">VGG 又称 VGG-16 网络，“16”指网络中卷积层和全连接层一共有16个。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="f9d3396f-f5f9-4deb-9379-780638272374" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">超参数较少，只需要专注于构建卷积层。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="51232a44-082f-4490-962d-38989b51194e" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">结构不复杂且规整，都是几个卷积层后面跟着可以压缩图像大小为原来一半的池化层，池化层缩小图像的高度和宽度到原来一半。同时，卷积层的卷积核都是Same Padding，并且数量变化存在一定的规律，由 64 翻倍变成 128，再到 256 和 512。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="021cbb5d-7e7a-4907-847f-218a78ce40d3" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">主要缺点是VGG 需要训练的特征数量巨大，包含多达约 1.38 亿个参数。</div></div></div></div></div><div class="notion-selectable notion-sub_header-block" data-block-id="4c7bd6ab-a4f3-45a3-bd13-bd0b5b707d2a" style="width: 100%; max-width: 1718px; margin-top: 1.4em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 2" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.5em; line-height: 1.3;">残差网络（Residual Network）</div></div></div><div class="notion-selectable notion-text-block" data-block-id="8fa2713d-bc29-4807-8627-6b90c871422f" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">非常深的网络是很难训练的，主要问题是梯度消失和梯度爆炸的情况会导致梯度信息不能很好的传到深处的网络中去。但是如果我们引入一种跳连（Skip connection）的方法，可以直接把前侧层直接连接到后侧层上去，使得梯度下降的时候能够更多快好省地传递梯度。</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="6a975707-eafc-4be1-a02b-23c8677266e2" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="6cc566c6076f6676d39a05a686d5cae2ea074dde.jpg" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="0c37675c-425b-46b6-b698-ab4761939f25" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">上图的结构就被称为<span class="notion-enable-hover" data-token-index="1" style="font-weight:600">残差块（Residual Network）</span>。具体来说我们可以写出如下表达式： $$
\begin{aligned}
z^{[l+1]}&amp;=W_1^Ta^{[l]}+b^{[l+1]}\\
a^{[l+1]}&amp;=g(z^{[l+1]})\\
z^{[l+2]}&amp;=W_2^Ta^{[l+1]}+b^{[l+2]}\\
a^{[l+2]}&amp;=g(z^{[l+2]}+a^{[l]})
\end{aligned}
$$ 注意在最后一步中，我们把<span class="notion-enable-hover" data-token-index="5" style="font-style:italic">z</span>[<span class="notion-enable-hover" data-token-index="7" style="font-style:italic">l</span> + 2]和<span class="notion-enable-hover" data-token-index="10" style="font-style:italic">a</span>[<span class="notion-enable-hover" data-token-index="12" style="font-style:italic">l</span>]相加后再代入激活函数，为了能让它们相加，我们需要两个矩阵有一样的形状。而一个残差网络的构建就是把很多残差块叠加在一起：</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="69863769-d196-447b-8619-7464f7e3c8c1" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="cab2136a894b567de434852e4b533ed2bf8086a4.jpg" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="311c1635-da6b-4da7-8fc9-445defd55009" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">如果使用标准优化算法训练一个普通网络，比如说梯度下降法，或者其它热门的优化算法。如果没有残差或者跳跃连接，会发现随着网络深度的加深，训练错误会先减少后增多。但有了 ResNets 就不一样了，即使网络再深，训练的表现也很不错。</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="03ceaae5-7069-4f36-8a34-fd5569fdaec9" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="95dfdcfbe688a9d04966d5a4a51883750dd6776e.jpg" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="c6fbcf71-a482-404b-ba6a-23d0e1e06a7b" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">为什么残差网络能够促进深度网络的学习</div></div></div><div class="notion-selectable notion-text-block" data-block-id="f770e944-8b58-4fc8-9dbc-7427060741ee" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">我们可以考虑这样一个情况：现在有一个已经很大的全部使用ReLU激活函数的神经网络，我们在它的末端再附加上一个残差块：</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="b2c205c4-778f-4ede-9ef7-7bf0634b23e7" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="5f1b29a2fa81d0325ebea0bb0300e7b35d8b9ac1.jpg" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="e537cdba-7cdd-4ac3-b4ac-1b0b6fe2213d" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">对于这个残差块，我们有： $$
\begin{aligned}
a^{[l+2]}&amp; =g(z^{[l+2]}+a^{[l]})\\&amp;=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})
\end{aligned}
$$ 如果我们的<span class="notion-enable-hover" data-token-index="3" style="font-style:italic">W</span>[<span class="notion-enable-hover" data-token-index="5" style="font-style:italic">l</span> + 2]和<span class="notion-enable-hover" data-token-index="8" style="font-style:italic">b</span>[<span class="notion-enable-hover" data-token-index="10" style="font-style:italic">l</span> + 2]都为0的话，由于<span class="notion-enable-hover" data-token-index="13" style="font-style:italic">a</span>[<span class="notion-enable-hover" data-token-index="15" style="font-style:italic">l</span>]本身是ReLU函数的输出，因此它的值大于零，在这样的情况下我就有<span class="notion-enable-hover" data-token-index="18" style="font-style:italic">a</span>[<span class="notion-enable-hover" data-token-index="20" style="font-style:italic">l</span> + 2] = <span class="notion-enable-hover" data-token-index="23" style="font-style:italic">R</span><span class="notion-enable-hover" data-token-index="24" style="font-style:italic">e</span><span class="notion-enable-hover" data-token-index="25" style="font-style:italic">L</span><span class="notion-enable-hover" data-token-index="26" style="font-style:italic">U</span>(<span class="notion-enable-hover" data-token-index="28" style="font-style:italic">a</span>[<span class="notion-enable-hover" data-token-index="30" style="font-style:italic">l</span>]) = <span class="notion-enable-hover" data-token-index="33" style="font-style:italic">a</span>[<span class="notion-enable-hover" data-token-index="35" style="font-style:italic">l</span>]。这等于是说这个网络的复杂程度并没有上升。观察残差块的结构我们可以发现，残差块可以很容易地传递恒等函数关系，或者说，我们可以在不减少网络层数或者拟合能力的情况下，为网络提供了一个传递恒等关系的能力。因此添加残差块就可以增强网络表现。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="0fcb88f6-1bbe-42eb-96a3-02ddb5869658" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">由于残差块中需要把<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">a</span>[<span class="notion-enable-hover" data-token-index="3" style="font-style:italic">l</span>]和<span class="notion-enable-hover" data-token-index="6" style="font-style:italic">z</span>[<span class="notion-enable-hover" data-token-index="8" style="font-style:italic">l</span> + 2]相加，对两个值的尺寸提出要求。如果我们两处尺寸不一样要怎么办呢？我们可以把<span class="notion-enable-hover" data-token-index="11" style="font-style:italic">a</span>[<span class="notion-enable-hover" data-token-index="13" style="font-style:italic">l</span>]乘上一个可学习参数（也可以设置成固定值）<span class="notion-enable-hover" data-token-index="16" style="font-style:italic">W</span><span class="notion-enable-hover" data-token-index="17" style="font-style:italic">s</span>，使得<span class="notion-enable-hover" data-token-index="19" style="font-style:italic">W</span><span class="notion-enable-hover" data-token-index="20" style="font-style:italic">s</span><span class="notion-enable-hover" data-token-index="21" style="font-style:italic">A</span>[<span class="notion-enable-hover" data-token-index="23" style="font-style:italic">l</span>]可以和<span class="notion-enable-hover" data-token-index="26" style="font-style:italic">z</span>[<span class="notion-enable-hover" data-token-index="28" style="font-style:italic">l</span> + 2]相加。按照这样的方法，我们就可以通过在一个普通网络里添加跳层连接把它变成一个残差网络了：</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="698b8b06-60ce-4320-9638-bc062b6c445c" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="4dd22d6586a48e3236f036d8093f9aae74c89d35.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-sub_header-block" data-block-id="a52ac5bb-d6ee-4c21-b48f-566696c7b5c3" style="width: 100%; max-width: 1718px; margin-top: 1.4em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 2" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.5em; line-height: 1.3;">Inception 网络</div></div></div><div class="notion-selectable notion-text-block" data-block-id="2202d430-39d4-4315-a778-2d4f93ff7175" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">在了解Inception网络是如何工作的之前，让我们先了解一下一种特殊的卷积——1x1卷积。</div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="f532b6ed-685e-4cd9-a771-0bd928291b49" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">1x1 卷积（1x1 convolution，或称为 Network in Network）</div></div></div><div class="notion-selectable notion-text-block" data-block-id="46b60c3e-0308-452d-a2bd-8c0adbc8aa02" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">1x1 卷积指的是卷积核的长宽都为1，步长stride为0，没有padding的卷积操作。我们可以发现它的计算有着如下的规律：</div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="0f1f0189-305d-428c-af39-d7b9bb9fae53" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">当通道数为 1 时，我们的1x1卷积就等价于把输入点乘一个标量再输出；</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="e0570a8a-6a56-4e5e-a03c-d2cb46b438ed" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">当通道数不为1时，1x1卷积就是把输入里的每一个像素的<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="2" style="font-style:italic">c</span>个通道值加权求和后按照一样的图像尺寸输出。</div></div></div></div></div><div class="notion-selectable notion-bulleted_list-block" data-block-id="94f95ebf-19a5-480a-b83a-55e52e7c45c7" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: 24px; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><div class="pseudoBefore" style='font-size: 1.5em; line-height: 1; margin-bottom: 0px; --pseudoBefore--fontFamily:Arial; --pseudoBefore--content:"•";'></div></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">如果我们的1x1卷积核个数有<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span>′<span class="notion-enable-hover" data-token-index="3" style="font-style:italic">c</span> &gt; 1个，那么我们就会按照对输入像素的不同通道使用<span class="notion-enable-hover" data-token-index="5" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="6" style="font-style:italic">c</span>′套的加权求和并输出一张<span class="notion-enable-hover" data-token-index="8" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="10" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="12" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="13" style="font-style:italic">c</span>′的特征图。</div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="8ead8735-7878-4956-ad52-46ba889a2453" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-weight:600">但是为什么我们要使用1x1卷积呢？</span>Google的论文里提到认为由于卷积核在面对有非常多通道数的输入时会产生大量的参数（<span class="notion-enable-hover" data-token-index="2" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="4" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="6" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="7" style="font-style:italic">c</span>个，如果这一层有多个卷积核则更多），而1x1卷积可以有效的缩小输入通道数，可以起到减少参数的作用。但是实际上我认为这么说还不足以使我们真正理解1x1卷积的作用。要理解1x1卷积，我认为我们需要先理解卷积都做了什么。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="7aafdd7c-5111-48b6-8113-43796e846abe" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">首先，我们知道在卷积操作中往往会形成很多通道，每个通道其实都表达了图片在这个区域的某一种特征是否出现。比如对于卷积神经网络中的第一层的结果，可能第一层包含了图片中有没有竖直纹理的信息，第二层包含了图片某个位置有没有水平纹理的信息，第三层可以判断图片的某个位置是否有小黑点……那么当我们使用1x1卷积时，我们就是把这些特征信息按照一定比例融合在了一起。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="a547c65b-c530-4ada-b610-faad5b3a134c" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">接下来让我们看一个简单的1x1卷积的例子：输入一张<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="3" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="5" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="6" style="font-style:italic">c</span>的输入图像进入一个1 × 1卷积后，对于得到<span class="notion-enable-hover" data-token-index="8" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="10" style="font-style:italic">n</span> × 1的输出图像，我们不使用激活函数，直接将它连接一个3 × 3 × 1的卷积。</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="86f0d516-e588-4d16-89a8-5b21e233d6b0" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="2091c114bc4b67252b568a0a93a344e0204a4406.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="38160b6d-95f6-429d-be46-ca940aed07ce" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">这个操作等价于单个卷积操作：</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="ad76e410-ef1a-44f9-90ff-6161eee6fa17" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="cfb6dd2ea6c397db1fe86193bc3987f682721d2d.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="f7809093-acaf-4944-9cf8-1456870c48b0" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">新的卷积核同样是一个3 × 3 × <span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="2" style="font-style:italic">c</span>的卷积核，但是需要的参数却少得多。这样的一个复合卷积核和真正的3 × 3 × <span class="notion-enable-hover" data-token-index="4" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="5" style="font-style:italic">c</span>卷积核差距在哪里呢？我们可以注意到，这个卷积核的层和层之间不再相互独立，而是按比例分布。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="2326f5f2-b9bb-4e43-a3b9-9790b3dc7735" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">这就是使我们的复合卷积核也能很好工作的假设：<span class="notion-enable-hover" data-token-index="1" style="font-weight:600">提取的新特征是低一级特征按照相同比例在特定区域激活的结果</span>。这句话什么意思呢，比如我们想要检测一个十字纹理的圈，那么我们会希望那些同时有水平和竖直纹理的特征点按照环形排列，环形位置上的每一个点，都具有高激活的水平特征和垂直纹理特征，而其他特征的激活都较低。这种情况就满足了我们的复合卷积核的假设。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="ed9c4df2-90f7-419c-b128-2bb6bddca1ea" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">这个理解只是一个方面，1x1卷积还有一个可能更加重要的作用：当我们有非常非常多的特征通道时，后面的卷积核提取特征可能并不需要用上所有的特征通道，那么这个时候1x1卷积就可以有选择的选出那些重要的特征通道，而后面的卷积核依然可以有效的捕获特征信息——原先我们依然要为那些每个不重要的特征分配<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="3" style="font-style:italic">f</span>个都很接近0的参数值，而现在有了1x1卷积我们只需要一个参数就能否决这个特征进入下一层的权利！</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="534f15d1-89b8-47b6-b299-06cb27464be1" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">以上只是我个人未经验证的猜想。那么以上这个假设是否真的是1x1卷积工作的原因呢？其实我也不能肯定。但是我有一个挺好的验证办法——去找一个训练过的普通卷积神经网络里拿一个比较大的卷积核出来，只要我们对它做奇异值分解，观察一下它的奇异值：如果它的奇异值中只有两个值比较大，剩下的都很接近零，那么这就说明事实上卷积核确实很容易被拆分为单层卷积和1x1卷积复合的结果。希望有条件的观众们可以愿意试一试或者看看有没有别人的相关工作并告诉我结果。（事实上可能并不能验证我的猜想，看到后面的关于MobileNet的内容时我们就会明白）</div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="655e7874-db72-45e2-84ca-0800786470f9" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">Inception 网络简介</div></div></div><div class="notion-selectable notion-text-block" data-block-id="c598233d-82c8-4006-9ff0-1fcb929234a4" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">现在让我们把目光移回Inception网络：inception网络的基本思想是小孩子才在每一层都思考使用1 × 1卷积，3 × 3卷积，5 × 5卷积还是池化操作，为什么我们不全都用上呢？</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="7833cdfb-e43f-481f-beb7-3eb892f0a309" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="0833a403b7a31da711fd19e8100147dbcaaa58f0.jpg" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="f1085dca-8655-43e3-98f3-f03ba066a9dd" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">如图所示，对于一个特征图，我们分别进行几种计算以后再把他们沿着通道方向连在一起。注意，为能够把他们沿着通道方向加在一起，我们的各种操作都要使用Padding来保证不改变图像的大小。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="c44ac510-c0e6-41f4-a341-5ddc2a1c8858" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">这个网络的问题也显而易见：每层都进行这么多计算，势必需要非常多的参数，计算量就成了一个大问题。这时，我们刚才的1x1卷积就可以派上用场了。</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="53627dc8-e016-4850-83f6-60b61ba511df" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="1aa4005c168841d3005a9d6b262d350c086a48f3.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="0a37d723-64a5-4013-be3c-da9f251aaa5f" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">如图我们先使用1x1卷积把图像通道缩小到一个较小的值，然后再使用卷积核进行卷积操作。这个 1x1 的卷积层通常被称作<span class="notion-enable-hover" data-token-index="1" style="font-weight:600">瓶颈层（Bottleneck layer）</span> 。在每个卷积处都使用一个瓶颈层，我们就可以大大减小参数数量。一通计算你会发现：参数量减少了90%左右。</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="d34bbc71-1999-4b2f-b3e5-b806a6429fac" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="c3018bf0b14037c3c2fa82e8a3d9aa7da014447a.jpg" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="e75973cf-48c6-44f0-a063-6431f49fa46d" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-weight:600">重要的细节：</span>瓶颈层缩小参数的方法看似很有用，为什么我们不在每一个卷积层之前都上一个瓶颈层呢？遇到这么好的事情，我们不禁会想：那么，代价是什么呢？这么这里我们稍微想一想就会知道：瓶颈层的作用恰如其名，这里1 × 1卷积的方法把所有通道加权求和，势必要选择性的丢失一些信息，本质上是在筛选出有用的通道减少卷积层的压力。那么那些被筛选掉的（分配了很小权重）的特征图怎么办呢？在一般的网络里如果我们这么用就会导致这些特征图白忙活了，他们再也没有任何机会被传到后方网络中。而Inception网络敢这么用的原因正是每一层都有数个并行的瓶颈层保证了信息的“流量”：我们发现把三个瓶颈层的通道数加上MaxPOOL的通道数差不多就是输入层的通道数——Inception把握得住信息。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="92ca1ba8-aed7-4200-b581-05ad4e687bf5" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">一个Inception的网络就是大量的Inception模块连成的，它完全体就长这样：</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="0172d04b-e2af-43ee-a66a-562d6ba0e49c" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="3d048531b35547b335b3550c29018746bd02fef0.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="c8585dcf-a83b-49c8-a033-66392a6c9f6c" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">可以看到Inception有多个输出，这是通过在网络中央监督来促进训练的辅助方法。Inception里可没有跳层连接，这样一个大块头很容易就会发生梯度消失和过拟合，因此在网络中央就进行监督有助于前部网络更好的学习。</div></div></div></div><div class="notion-selectable notion-sub_header-block" data-block-id="8d3815a2-f377-4e20-bd12-638dfad614ee" style="width: 100%; max-width: 1718px; margin-top: 1.4em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 2" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.5em; line-height: 1.3;">MobileNet</div></div></div><div class="notion-selectable notion-text-block" data-block-id="ee9e605a-7694-4221-adfc-4a85ed467836" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">MoblieNet其实就类似于我们上面提到的使用瓶颈层来减少计算量的一种网络，这种网络可以使得我们在不损失很多精度的情况下，把那些原先根本无法在移动设备上运行的神经网络部署到移动设备上。不过它使用的并不是真正的瓶颈层，而是一种可以看作是“反瓶颈层”的一种结构。让我们开始吧。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="9ff496c6-3b4e-4948-b3ff-313088cdb455" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">MobileNet的核心就是<span class="notion-enable-hover" data-token-index="1" style="font-weight:600">可按层分离的卷积操作（Depthwise Separable Convolution）</span>：</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="3f2a6c78-685c-4751-99be-8d676d488a38" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="f530366bdb11581552ba6ab328c32763c96dd20d.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="0cbf140c-53d2-4079-8015-b73d69cc903d" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">上图上部分是一般的卷积操作，<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="3" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="5" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="6" style="font-style:italic">c</span>大小的卷积核作用在<span class="notion-enable-hover" data-token-index="8" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="10" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="12" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="13" style="font-style:italic">c</span>的图像上，得到一个单层的特征图。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="f3e8a63f-ab1f-4c7a-ad4d-8a1394490fd0" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">上图下一部分就是MobileNet使用的可按层分离的卷积操作，原来一次的卷积划分为了两次特殊的卷积：</div></div></div></div><div class="notion-selectable notion-numbered_list-block" data-block-id="11d16059-843e-4412-b075-e8ff4d3b2655" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: unset; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><span class="pseudoBefore" style='--pseudoBefore--content:"1."; text-align: center; white-space: nowrap; width: 24px;'></span></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">第一部分是<span class="notion-enable-hover" data-token-index="1" style="font-weight:600">按深度的卷积（Depthwise Convolution）</span>，<span class="notion-enable-hover" data-token-index="3" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="5" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="7" style="font-style:italic">n</span>大小的卷积核作用在<span class="notion-enable-hover" data-token-index="9" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="11" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="13" style="font-style:italic">n</span>的图像上，这时得到的却是一个有<span class="notion-enable-hover" data-token-index="15" style="font-style:italic">n</span>个通道的特征图：每一层卷积核分别作用在每一层的输入图像上（第一层<span class="notion-enable-hover" data-token-index="17" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="19" style="font-style:italic">f</span> × 1的卷积层卷积在第一层的<span class="notion-enable-hover" data-token-index="21" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="23" style="font-style:italic">n</span> × 1的输入图像上，得到的特征图作为输出特征图的第一层，以此类推）这样我们就得到了一个中间特征图。</div></div><div class="notion-selectable notion-text-block" data-block-id="dab5aaec-f3e2-4cd0-9f5c-00390d729dd4" style="width: 100%; max-width: 100%; margin-top: 2px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-style:italic">c</span></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="d8013d99-e992-4268-b32e-1971ee975367" style="width: 100%; max-width: 100%; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-style:italic">c</span></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="f2dddc52-2a84-45ba-957c-e58c66dd229b" style="width: 100%; max-width: 100%; margin-top: 1px; margin-bottom: 0px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-style:italic">c</span></div></div></div></div></div></div></div><div class="notion-selectable notion-numbered_list-block" data-block-id="96636f3d-7926-4abf-85f0-02e0abb6f87b" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="display: flex; align-items: flex-start; width: 100%; padding-left: 2px; color: inherit; fill: inherit;"><div class="pseudoSelection" contenteditable="false" data-content-editable-void="true" data-text-edit-side="start" style="user-select: none; --pseudoSelection--background:transparent; margin-right: 2px; width: unset; display: flex; align-items: center; justify-content: center; flex-grow: 0; flex-shrink: 0; min-height: calc(1.5em + 3px + 3px);"><span class="pseudoBefore" style='--pseudoBefore--content:"2."; text-align: center; white-space: nowrap; width: 24px;'></span></div><div style="flex: 1 1 0px; min-width: 1px; display: flex; flex-direction: column;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="List" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; text-align: left;">第二部分是一个1x1卷积，正是这一层卷积将我们原来的<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span>个通道的中间特征图转为我们需要通道数的输出特征图。</div></div><div class="notion-selectable notion-text-block" data-block-id="58ca74d3-7869-4ebc-9bb3-6216d823804b" style="width: 100%; max-width: 100%; margin-top: 2px; margin-bottom: 0px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-style:italic">c</span></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="43730c03-2994-48ea-930b-6493908cde79" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">这种可按层分离的卷积操作可以大大减小卷积需要的参数数量。如果我们把这种卷积和输出通道<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="2" style="font-style:italic">c</span>′，卷积核大小<span class="notion-enable-hover" data-token-index="4" style="font-style:italic">f</span> × <span class="notion-enable-hover" data-token-index="6" style="font-style:italic">f</span>的一般卷积对比，它需要的参数只有原来的$\left(\frac1{n_c'}+\frac1{f^2}\right)$倍。</div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="c808e9b7-5e1e-440b-8a9d-f2996e671f31" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">为什么MobileNet效果好</div></div></div><div class="notion-selectable notion-text-block" data-block-id="29155b96-a773-4b3d-8519-bbbcd982c047" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">天下没有免费的午餐，为什么我们可以在大大减少参数的同时相对维持网络表现呢？这里是否存在一个加在一般卷积网络的一个更强的假设，在这种假设下可以消去冗余的参数，而这种假设恰好是很多视觉任务都满足的呢？我们不妨思考一下：在可按层分离的卷积操作中，我们最终得到的<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="2" style="font-style:italic">c</span>′个通道的特征图都来自于1x1卷积操作。而不同1x1卷积核实际上做的就是对按层卷积的输出结果（也就是中间特征图）在通道上的加权求和。那么我们就可以知道，MobileNet可以和一般卷积网络达到一样的效果需要的前提是：<span class="notion-enable-hover" data-token-index="4" style="font-weight:600">同一层中不同特征的构建需要的卷积核权重是相同的</span>。</div></div></div></div><div class="notion-selectable notion-sub_sub_header-block" data-block-id="5c6acbb7-42bf-4aba-a90e-2b7190a6c382" style="width: 100%; max-width: 1718px; margin-top: 1em; margin-bottom: 1px;"><div style="display: flex; width: 100%; color: inherit; fill: inherit;"><div contenteditable="false" data-content-editable-leaf="true" placeholder="Heading 3" spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px; font-weight: 600; font-size: 1.25em; line-height: 1.3;">MobileNet和MobileNet v2</div></div></div><div class="notion-selectable notion-text-block" data-block-id="153e032d-6c2b-4beb-ba4d-872df8858b43" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">MobileNet的完整结构就是把Depthwise Separable Convolution叠加13次得到了一个完整的MoblieNet结构。但是我们之前知道了MobileNet不损失精确度需要的前提是：同一层中不同特征的构建需要的卷积核权重是相同的。这似乎并不好达到——要求不同的特征提取需要的卷积核长得一模一样显然要求有点高。那么是不是如果我们可以允许不同的特征需要的卷积核有一定差别，这个假设是不是就更容易满足，MobileNet就更强了？接下来让我们有请MobileNet v2（这个想法只是我的猜想，不清楚论文作者是不是这么想的）</div></div></div></div><div class="notion-selectable notion-image-block" data-block-id="aae860a4-e731-46ec-b224-87880b156254" style="width: 100%; max-width: 1910px; align-self: center; margin-top: 4px; margin-bottom: 4px;"><div contenteditable="false" data-content-editable-void="true"><div style="display: flex;"><div class="notion-cursor-default" style="position: relative; overflow: hidden; flex-grow: 1;"><div style="position: relative;"><div><div><img referrerpolicy="same-origin" src="82d283a660849565bca8eafa7c72dd0f6629251a.png" style="display: block; object-fit: cover; border-radius: 1px; background: white; pointer-events: auto; width: 100%;"/></div></div></div></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="734c219b-5b27-421d-bc93-2fbd9c91a22b" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">MobileNet v2借鉴了resNet的设计使用了skip-connection。而被称为是Bottleneck的结构中，MobileNet v2引入了一个总是把通道数翻六倍的1x1卷积，使得原来只有<span class="notion-enable-hover" data-token-index="1" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="2" style="font-style:italic">c</span>层的卷积核现在可以有6<span class="notion-enable-hover" data-token-index="4" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="5" style="font-style:italic">c</span>层了。我们先把<span class="notion-enable-hover" data-token-index="7" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="8" style="font-style:italic">c</span>个通道线形变换到6<span class="notion-enable-hover" data-token-index="10" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="11" style="font-style:italic">c</span>个通道，再进行6<span class="notion-enable-hover" data-token-index="13" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="14" style="font-style:italic">c</span>次的按通道卷积操作，最后再把他们进行1x1卷积变回<span class="notion-enable-hover" data-token-index="16" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="18" style="font-style:italic">n</span> × <span class="notion-enable-hover" data-token-index="20" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="21" style="font-style:italic">c</span>的输出向量。现在我们注意到，只要每个通道的输出特征图需要的卷积核都可以由6<span class="notion-enable-hover" data-token-index="23" style="font-style:italic">n</span><span class="notion-enable-hover" data-token-index="24" style="font-style:italic">c</span>个卷积核线形组合得到，我们的MobileNet和普通网络的表现一样好的条件就能被满足。</div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="ce91d261-39eb-490d-81c7-3d84f40c088b" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 1px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;"><span class="notion-enable-hover" data-token-index="0" style="font-weight:600">参考资料：</span></div></div></div></div><div class="notion-selectable notion-text-block" data-block-id="33b53fa4-5e41-4c30-adbc-10c653e70ef7" style="width: 100%; max-width: 1718px; margin-top: 1px; margin-bottom: 0px;"><div style="color: inherit; fill: inherit;"><div style="display: flex;"><div contenteditable="false" data-content-editable-leaf="true" placeholder=" " spellcheck="true" style="max-width: 100%; width: 100%; white-space: pre-wrap; word-break: break-word; caret-color: rgb(55, 53, 47); padding: 3px 2px;">[1] Coursera Deeplearning.AI深度学习教程：https://www.coursera.org/specializations/deep-learning</div></div></div></div></div></div><div contenteditable="false" data-content-editable-void="true" style="width: 0px;"><div style="display: none; flex-shrink: 0; pointer-events: none; width: 0px; position: absolute; right: 192px; opacity: 0;"><div style="display: flex; flex-direction: column; padding: 5px 16px; width: 340px; flex-shrink: 0; height: 100%; position: relative; pointer-events: none; z-index: 1;"><div style="position: absolute; pointer-events: none; width: 100%; height: 100%; top: -5px; background: linear-gradient(white 0px, rgba(255, 255, 255, 0) 15px);"></div></div></div></div></main><span style="height: 1px; width: 1px;"></span></div><div class="notion-presence-container" style="position: absolute; top: 0px; left: 0px; z-index: 89;"><div></div></div></div></div></div><div class="notion-peek-renderer" style="position: fixed; top: 0px; right: 0px; bottom: 0px; width: 960px; z-index: 109; transform: translateX(960px) translateZ(0px);"></div></div></div></div></div><script src="1172e9111a5fb396bcb8a05870b5eabf8abf221c.js" type="text/javascript"></script><div style="width: env(safe-area-inset-bottom);"></div></body></html>